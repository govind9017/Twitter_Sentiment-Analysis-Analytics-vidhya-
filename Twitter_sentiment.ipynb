{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# twitter sentiment analysis for classification of racist/sexist tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "# nltk.download(stopwords)\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"twitter_analysis/train.csv\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df['new_tweet'] = np.nan\n",
    "# df = df.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### only alphabets and hashtag (remove punctuation, numbers and special char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      user when a father is dysfunctional and is s...\n",
       "1     user  user thanks for #lyft credit i can t us...\n",
       "2                                  bihday your majesty\n",
       "3    #model   i love u take with u all the time in ...\n",
       "4               factsguide  society now    #motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.new_tweet = df.tweet.str.replace('[^a-zA-Z#]',' ')\n",
    "df.new_tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove word user and also words with length less than 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.new_tweet=df.new_tweet.apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "df.new_tweet=df.new_tweet.apply(lambda x: ' '.join([w for w in x.split() if w != \"user\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    when father dysfunctional selfish drags kids i...\n",
       "1    thanks #lyft credit cause they offer wheelchai...\n",
       "2                                  bihday your majesty\n",
       "3                           #model love take with time\n",
       "4                       factsguide society #motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.new_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in tqdm(range(len(df))):\n",
    "#     filtered_sent=[]\n",
    "#     for x in df.new_tweet[i].split():\n",
    "#         x = str(TextBlob(x).correct())\n",
    "#         x = st.stem(x)\n",
    "#         if x.lower() not in stop:\n",
    "#             filtered_sent.append(x.lower())\n",
    "#     df.new_tweet[i] = \" \".join(filtered_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = df.new_tweet.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling Correction with stemmingg and conert words to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new = df_new.apply(lambda x: [st.stem(str(TextBlob(i).correct())).lower() for i in x if i.lower() not in stop])\n",
    "# df_new = df_new.apply(lambda x: [st.stem(i) for i in tqdm(x)])\n",
    "# df_new = df_new.apply(lambda a: [x.lower() for x in tqdm(a) if x.lower() not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_new.to_csv('processed_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = df_new.apply(lambda y: ' '.join(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_new.to_csv('processed_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Column 'processed_tweets' contains preprocessed tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>processed_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>father dysfunct selfish drag kiss dysfunct #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thank #left credit caus offer wheelchair van #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>midday majesti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model love take time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguid societi #motiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                    processed_tweets  \n",
       "0    father dysfunct selfish drag kiss dysfunct #run  \n",
       "1  thank #left credit caus offer wheelchair van #...  \n",
       "2                                     midday majesti  \n",
       "3                              #model love take time  \n",
       "4                           factsguid societi #motiv  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_tweets']=df_new\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('twitter_analysis/processed_tweet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "label               0\n",
       "tweet               0\n",
       "processed_tweets    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['tweet'].apply(lambda x: x.split()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                | 0/31962 [00:00<?, ?it/s]\n",
      "  0%|                                      | 32/31962 [00:00<01:43, 307.69it/s]\n",
      "  3%|█▏                                 | 1099/31962 [00:00<00:05, 5309.18it/s]\n",
      "  8%|██▊                                | 2553/31962 [00:00<00:03, 8288.97it/s]\n",
      " 13%|████▍                             | 4151/31962 [00:00<00:02, 10174.02it/s]\n",
      " 19%|██████▍                           | 6061/31962 [00:00<00:02, 11588.91it/s]\n",
      " 25%|████████▍                         | 7979/31962 [00:00<00:01, 12506.27it/s]\n",
      " 30%|██████████                        | 9470/31962 [00:00<00:01, 12814.62it/s]\n",
      " 34%|███████████▎                     | 10953/31962 [00:00<00:01, 13008.31it/s]\n",
      " 40%|█████████████                    | 12677/31962 [00:00<00:01, 13302.21it/s]\n",
      " 45%|██████████████▊                  | 14304/31962 [00:01<00:01, 13430.99it/s]\n",
      " 49%|████████████████▎                | 15744/31962 [00:01<00:01, 13410.56it/s]\n",
      " 54%|█████████████████▋               | 17164/31962 [00:01<00:01, 13315.75it/s]\n",
      " 58%|███████████████████▎             | 18681/31962 [00:01<00:00, 13439.57it/s]\n",
      " 63%|████████████████████▊            | 20128/31962 [00:01<00:00, 13508.72it/s]\n",
      " 68%|██████████████████████▌          | 21881/31962 [00:01<00:00, 13624.53it/s]\n",
      " 73%|████████████████████████         | 23366/31962 [00:01<00:00, 13672.32it/s]\n",
      " 78%|█████████████████████████▉       | 25066/31962 [00:01<00:00, 13742.33it/s]\n",
      " 83%|███████████████████████████▍     | 26584/31962 [00:01<00:00, 13809.87it/s]\n",
      " 88%|████████████████████████████▉    | 28052/31962 [00:02<00:00, 13771.23it/s]\n",
      " 92%|██████████████████████████████▍  | 29524/31962 [00:02<00:00, 13809.17it/s]\n",
      " 98%|████████████████████████████████▏| 31185/31962 [00:02<00:00, 13884.69it/s]\n",
      "100%|█████████████████████████████████| 31962/31962 [00:02<00:00, 13878.42it/s]"
     ]
    }
   ],
   "source": [
    "positive_sent = []\n",
    "negative_sent = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    if df['label'][i]==1:\n",
    "        for x in df['processed_tweets'][i].split():\n",
    "            negative_sent.append(x)\n",
    "    else:\n",
    "        for x in df.processed_tweets[i].split():\n",
    "            positive_sent.append(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# M1 --> for i in set(negative_sent):\n",
    "#     negative_sent.count(i)\n",
    "positive_sentences = \" \".join(positive_sent)\n",
    "negative_sentences = \" \".join(negative_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most counts words in non racist/sexist tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happi     1759\n",
       "#love     1716\n",
       "love      1544\n",
       "time      1191\n",
       "today     1016\n",
       "thank     1005\n",
       "like       982\n",
       "make       954\n",
       "#posit     835\n",
       "good       796\n",
       "want       756\n",
       "peopl      749\n",
       "father     741\n",
       "life       740\n",
       "take       728\n",
       "look       716\n",
       "#smile     674\n",
       "come       673\n",
       "day        659\n",
       "feel       648\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_pos_freq = pd.Series(positive_sentences.split()).value_counts()[:20]\n",
    "top_pos_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most count words in racist/sexist tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "racism        173\n",
       "like          145\n",
       "white         143\n",
       "#tramp        136\n",
       "black         103\n",
       "#polit         95\n",
       "#allahsoil     92\n",
       "stop           88\n",
       "peopl          84\n",
       "tramp          77\n",
       "might          77\n",
       "#librari       76\n",
       "#saw           75\n",
       "#liber         75\n",
       "librari        73\n",
       "women          68\n",
       "call           64\n",
       "#between       63\n",
       "feel           63\n",
       "listen         61\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_neg_freq = pd.Series(negative_sentences.split()).value_counts()[:20]\n",
    "top_neg_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FUNCTION TO EXTRACT HASHTAG WORDS\n",
    "def hashtag(x):\n",
    "    hashtags = []\n",
    "    for tweet in x:\n",
    "#         if re.search(r'#\\w+', tweet)!= None:\n",
    "        ht=re.findall(r\"#(\\w+)\", tweet)\n",
    "        hashtags.append(ht)\n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HASHTAG word with counts in racist/sexist tweeets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negative_hashtag=hashtag(df['processed_tweets'][df['label']==1])\n",
    "negative_hashtag = sum(negative_hashtag, [])\n",
    "# negative_hashtag[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tramp        136\n",
       "polit         95\n",
       "allahsoil     92\n",
       "librari       76\n",
       "saw           75\n",
       "liber         75\n",
       "between       63\n",
       "mimi          46\n",
       "black         46\n",
       "hate          37\n",
       "right         33\n",
       "drama         32\n",
       "camp          32\n",
       "ulm           28\n",
       "breast        27\n",
       "salari        27\n",
       "sigh          27\n",
       "tempt         26\n",
       "templ         26\n",
       "hispan        26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_neg_ht_words = pd.Series(negative_hashtag).value_counts()[:20]\n",
    "top_neg_ht_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HASHTAG word with counts in non racist/sexist tweeets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "love          1765\n",
       "posit          837\n",
       "smile          692\n",
       "thank          539\n",
       "healthi        529\n",
       "fun            464\n",
       "life           452\n",
       "happi          436\n",
       "affirm         423\n",
       "summer         399\n",
       "beauti         387\n",
       "model          377\n",
       "cut            371\n",
       "day            368\n",
       "blow           352\n",
       "follow         348\n",
       "friend         346\n",
       "fathersday     341\n",
       "girl           311\n",
       "silver         304\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_hashtag=hashtag(df['processed_tweets'][df['label']==0])\n",
    "positive_hashtag = sum(positive_hashtag, [])\n",
    "top_pos_ht_words = pd.Series(positive_hashtag).value_counts()[:20]\n",
    "top_pos_ht_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df[\"processed_tweets\"],df[\"label\"], test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6393"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf count words present in each and every tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(df['processed_tweets'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(x_train)\n",
    "xtest_tfidf =  tfidf_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest model to features defined by tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=200, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(xtrain_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(xtest_tfidf)\n",
    "prediction[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.963084623807\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy: 96%  on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('twitter_analysis/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.new_tweet = test.tweet.str.replace('[^a-zA-Z#]',' ')\n",
    "test.new_tweet=test.new_tweet.apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "test.new_tweet=test.new_tweet.apply(lambda x: ' '.join([w for w in x.split() if w != \"user\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_new = test.new_tweet.apply(lambda x: x.split())\n",
    "test_new = test_new.apply(lambda x: [st.stem(str(TextBlob(i).correct())).lower() for i in x if i.lower() not in stop])\n",
    "processed_test = test_new.apply(lambda y: ' '.join(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    #studiolif #dislik #requir #passion #educ #wil...\n",
       "1         #white #supremacist want everyon #bird #movi\n",
       "2        safe way heal #acn #altwaystoh #healthi #heal\n",
       "3    curs child book reserv alreadi #harrypott #pot...\n",
       "4    #midday amaz hilari #nephew their uncl dave lo...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['processed_tweets'] = processed_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('twitter_analysis/processed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_tfidf =  tfidf_vect.transform(test['processed_tweets'])\n",
    "predict_test = model.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy: 71% on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_result = pd.DataFrame({'id':test['id'],'label':predict_test})\n",
    "final_result.to_csv('output.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
